{"cells":[{"cell_type":"markdown","source":["<td>\n   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n</td>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"bd1df061-02be-4232-8016-4aeb27fd7691","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["# __*Labelbox Connector for Databricks Tutorial Notebook*__\n\n# _**Creating Data Rows with Metadata, Attachments and Annotations with LabelSpark**_"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"14187edd-08f4-4002-a90a-012c1c8857cc","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<td>\n<a href=\"https://github.com/Labelbox/labelspark/blob/master/notebooks/full-demo.ipynb\" target=\"_blank\"><img\nsrc=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n</td>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b2701875-c3d4-41cf-a964-a03129dbdd1d","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Thanks for trying out the Databricks and Labelbox Connector! You or someone from your organization signed up for a Labelbox trial through Databricks Partner Connect. This notebook was loaded into your Shared directory to help illustrate how Labelbox and Databricks can be used together to power unstructured data workflows. \n\nLabelbox can be used to rapidly annotate a variety of unstructured data from your Data Lake ([images](https://labelbox.com/product/image), [video](https://labelbox.com/product/video), [text](https://labelbox.com/product/text), and [geospatial tiled imagery](https://docs.labelbox.com/docs/tiled-imagery-editor)) and the Labelbox Connector for Databricks makes it easy to bring the annotations back into your Lakehouse environment for AI/ML and analytical workflows. \n\nIf you would like to watch a video of the workflow, check out our [Data & AI Summit Demo](https://databricks.com/session_na21/productionizing-unstructured-data-for-ai-and-analytics). \n\n\n<img src=\"https://labelbox.com/static/images/partnerships/collab-chart.svg\" alt=\"example-workflow\" width=\"800\"/>\n\n<h5>Questions or comments? Reach out to us at [ecosystem+databricks@labelbox.com](mailto:ecosystem+databricks@labelbox.com)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"889e8c34-5b3d-4063-bbc9-0099251817ca","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## _**Documentation**_"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c02cc95a-899a-438f-9494-73b5befa4498","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### **Data Rows**\n_____________________\n\n**Requirements:**\n\n- A `row_data` column - This column must be URLs that point to the asset to-be-uploaded\n\n- Either a `dataset_id` column or an input argument for `dataset_id`\n  - If uploading to multiple datasets, provide a `dataset_id` column \n  - If uploading to one dataset, provide a `dataset_id` input argument\n    - _This can still be a column if it's already in your CSV file_\n\n**Recommended:**\n- A `global_key` column\n  - This column contains unique identifiers for your data rows\n  - If none is provided, will default to your `row_data` column\n- An `external_id` column\n  - This column contains non-unique identifiers for your data rows\n  - If none is provided, will default to your `global_key` column  \n\n**Optional:**\n- A `project_id` columm or an input argument for `project_id`\n  - If batching to multiple projects, provide a `project_id` column\n  - If batching to one project, provide a `project_id` input argument\n    - _This can still be a column if it's already in your CSV file_"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"eccb2677-9d24-471e-b525-56ecb426949e","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### **Attachments**\n_____________________\n\nFor attachments, the column name must be \" `attachment` + `divider` + `attachment_type` + `divider` + `column_name` \"\n  - Example: `attachment///raw_text///sample_column_name`\n  - `attachment_type` must be one of the following:\n    - `image`, `video`, `raw_text`, `html`, `text_url`\n\n\nValues for attachments must correspond with the attachment type per Labelbox docs\n  - More here: \n    - [Labelbox docs on attachments](https://docs.labelbox.com/docs/asset-attachments)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"162c05fb-38da-4d40-8287-89c3e6211e02","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### **Metadata**\n_____________________\nFor metadata, the column name must be \" `metadata` + `divider` + `metadata_type` + `divider` + `metadata_field_name` \"\n  - Example: `metadata///string///sample_metadata_field_name`\n  - `metadata_type` must be one of the following:\n    - `string`, `enum`, `datetime`, `number` \n  - If the `metadata_field_name` doesn't exist yet in Labelbox, LabelSpark will create it for you\n\n\nThe values for metadata fields must correspond with the metadata type per Labelbox docs\n  - More here:\n    - [Labelbox definition of metadata](https://docs.labelbox.com/docs/datarow-metadata)\n    - [Labelbox docs on creating metadata](https://docs.labelbox.com/docs/createmodify-metadata-schema)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f52efa6e-2a2f-48d3-ac3c-e51538c33239","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### **Annotations**\n_____________________\n\n*Note:*\n*There must also be a `project_id` column, or an input argument for `project_id` when using LabelSpark to upload annotations*\n\n*There must also be an `upload_method` provided when using LabelSpark*\n  - *`upload_method` must be one of the following:*\n    - *`\"mal\"` (uploads annotations as pre-labels)*\n    - *`\"import\"` (uploads annotations as submitted labels)*\n    \n\n- For annotations, the column name must be `annotation` + `divider` + `annotation_type` + `divider` + `top_level_feature_name`\n  - Example: `annotation///bbox///bbox_tool_name` where, in this case, the bounding tool name in your Labelbox ontology is \"bbox_tool_name\"\n  - `annotation_type` must be one of the following:\n    - `bbox`, `polygon`, `point`, `mask`, `line`, `named-entity`, `radio`, `checklist`, `text`\n- Values for annotations must correspond with the following, per annotation type:\n\n_____________________\n_____________________\n\n**Row-Level Formats for Tool Annotations**\n- `bbox` (this example is two annotations)\n```\n[\n        [[top, left, height, width], [nested_classification_name_paths]], \n        [[top, left, height, width], [nested_classification_name_paths]]\n]\n```\n- `polygon` (this example is two annotations)\n```\n[\n        [[(x, y), (x, y),...(x, y)], [nested_classification_name_paths]], \n        [[(x, y), (x, y),...(x, y)], [nested_classification_name_paths]]\n]\n```\n- `line` (this example is two annotations)\n```\n[\n        [[(x, y), (x, y),...(x, y)], [nested_classification_name_paths]], \n        [[(x, y), (x, y),...(x, y)], [nested_classification_name_paths]]\n]\n```\n- `point` (this example is two annotations)\n```\n[\n        [[x, y], [nested_classification_name_paths]], \n        [[x, y], [nested_classification_name_paths]]\n]\n```\n- `mask` (this example is two annotations)\n```\n[\n        [[URL, colorRGB], [nested_classification_name_paths]], \n        [[URL, colorRGB], [nested_classification_name_paths]]\n]\n                      OR\n[\n        [[numpy_array, colorRGB], [nested_classification_name_paths]], \n        [[numpy_array, colorRGB], [nested_classification_name_paths]]\n]\n                      OR\n[\n        [[png_bytes, None], [nested_classification_name_paths]], \n        [[png_bytes, None], [nested_classification_name_paths]]\n]\n```\n- `named-entity` (this example is two annotations)\n```\n[\n        [[start, end], [nested_classification_name_paths]], \n        [[start, end], [nested_classification_name_paths]]\n]\n```\n\n**Row-Level Formats for Classification Annotations**\n- `radio`, `checklist` and `text`\n```\n[[answer_name_paths]]\n```\n  - Note: the last string in a text name path is the text answer value itself\n_____________________\n_____________________"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"5f926ecb-690d-44d0-ab4c-e0dd2dbc4ccf","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## _**Code**_"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"06ff0dac-d4ab-4182-bd6a-735781250779","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Install LabelSpark"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d4f269c1-f02b-47e9-9e92-711493d26d24","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%pip install labelspark -q"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6c57f9d9-4886-4a84-90f9-1985b238211f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import labelspark as ls\n# Imported to create an example ontology - not required for typical runs of LabelSpark\nfrom labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0bc40908-37a9-4723-97cb-6a7d5fce7ab4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["table_name = \"labelspark_full_demo\" # Name to register test table under\ncsv_path = \"https://raw.githubusercontent.com/Labelbox/labelspark/master/datasets/full-import.csv\" # Path to your CSV file\napi_key = \"\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"acdfe8c6-1d76-46af-a945-162f5c8a1e26","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Load a CSV as a Spark Table"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a9d30902-fce5-494a-99d2-8b6c4780a8c9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pandas as pd\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('labelspark-demo').getOrCreate() # Create a Spark Session\ndf = pd.read_csv(csv_path) # Read CSV in as Pandas DataFrame\ntable = spark.createDataFrame(df) # Convert your Pandas DataFrame into a Spark DataFrame"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"cc3a398f-cb16-48d8-81c5-8fd2da9ff833","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Register your Spark Table (for this demo, we will only save as a temporary table)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e4811378-84d6-4e3b-9553-c98b98578a26","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["tblList = spark.catalog.listTables()\n\nif not any([x.name == table_name for x in tblList]):\n  table.createOrReplaceTempView(table_name)\n  print(f\"Registered table: {table_name}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"bfaaf86c-3497-4096-a04e-95fa1bb3a576","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(sqlContext.sql(f\"select * from {table_name} LIMIT 5\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"24a15063-ee1b-49b4-8ee7-40f8f2ac8b46","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Create a project, dataset and ontology"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b186a2ad-0640-435e-88e8-a94b7439b3c3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["client = ls.Client(lb_api_key=api_key)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"548f5907-af40-49cd-bb5e-80385a2d5e98","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["project = client.lb_client.create_project(name=\"LabelSpark-full-demo\")\ndataset = client.lb_client.create_dataset(name=\"LabelSpark-full-demo\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d5eaac1a-1284-4785-b7e3-4ef64f09a267","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ontology_builder = OntologyBuilder(\n    classifications=[ \n        Classification( # Radio classification\n            class_type=Classification.Type.RADIO, instructions=\"sample_radio_question\", \n            options=[Option(value=\"sample_radio_answer_1\"), Option(value=\"sample_radio_answer_2\")]\n        ),\n        Classification( # Checklist classification\n            class_type=Classification.Type.CHECKLIST, instructions=\"sample_checklist_question\", \n            options=[Option(value=\"sample_checklist_answer_1\"), Option(value=\"sample_checklist_answer_2\")]\n        ), \n        Classification( # Text classification\n            class_type=Classification.Type.TEXT, instructions=\"sample_free_text_question\"\n        ),\n        Classification( # Radio classification where one answer has a nested radio classification\n            class_type=Classification.Type.RADIO, instructions=\"sample_nested_radio_question\",\n            options=[\n                Option(\n                    value=\"sample_branch_radio_answer_1\", \n                    options=[\n                        Classification(\n                            class_type=Classification.Type.RADIO, instructions=\"sample_sub_radio_question\", \n                            options=[Option(\"sample_sub_radio_answer_1\"), Option(\"sample_sub_radio_answer_2\")]\n                        )\n                    ]\n                ), \n                Option(value=\"sample_leaf_radio_answer_2\")\n            ]\n        )\n    ],\n    tools=[ # List of Tool objects\n        Tool( # Bounding Box tool\n            tool=Tool.Type.BBOX, name=\"sample_bounding_box\"), \n        Tool( # Bounding Box tool with a nested text classification\n            tool=Tool.Type.BBOX,  name=\"sample_nested_bounding_box\",\n            classifications=[\n                Classification(class_type=Classification.Type.TEXT, instructions=\"sample_tool_sub_text_question\"),]\n        ),\n        Tool( # Polygon tool\n            tool=Tool.Type.POLYGON, name=\"sample_polygon\"\n        ),\n        Tool( # Polygon tool with a nested radio classification\n            tool=Tool.Type.POLYGON, name=\"sample_nested_polygon\",\n            classifications=[\n                Classification(\n                    class_type=Classification.Type.RADIO, instructions=\"sample_tool_sub_radio_question\",\n                    options=[Option(\"sample_sub_radio_answer_1\"), Option(\"sample_sub_radio_answer_2\")]\n                ),\n            ]            \n        ),        \n        Tool( # Segmentation mask tool given the name \"mask\"\n            tool=Tool.Type.SEGMENTATION, name=\"sample_segmentation_mask\"\n        ),\n \t      Tool( # Point tool given the name \"point\"\n            tool=Tool.Type.POINT, name=\"sample_point\"\n        ), \n        Tool( # Polyline tool given the name \"line\"\n            tool=Tool.Type.LINE, name=\"sample_polyline\"\n        )\n    ]\n)\n\nontology = client.lb_client.create_ontology(\"LabelSpark-full-demo\", ontology_builder.asdict())\n\nproject.setup_editor(ontology)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"5ba94682-44a9-43fc-a8ac-cf3197fd8b5d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Upload to Labelbox"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e711f5c6-c99f-449d-83ef-4de53b5c11d4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["results = client.create_data_rows_from_table(\n    table = table,\n    dataset_id = dataset.uid,\n    project_id = project.uid,\n    upload_method = \"import\", # Must be either \"import\" or \"mal\"\n    skip_duplicates = False, # If True, will skip data rows where a global key is already in use\n    mask_method = \"png\", # Input masks must be either \"png\", \"url\", or \"array\"\n    verbose = True, # If True, prints information about code execution\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c81d65c8-b519-4331-9ac2-d4d8f23efc73","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"full-demo","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1809299167036817}},"nbformat":4,"nbformat_minor":0}
