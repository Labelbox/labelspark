{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Labelspark Cluster Creator</font></h1>\n",
    "<b>This Python script provides Labelbox customers with a simple and efficient way to automate the deployment of a Databricks cluster, which is pre-configured for optimum use with Labelbox services.\n",
    "The script performs two main tasks: creating a Databricks cluster with specific configurations and installing Labelbox-recommended Python libraries onto the newly created cluster.\n",
    "First, the script automatically sets up a Databricks cluster with configurations tailored for optimal use with Labelbox. These configurations include the number of workers, Spark version, node types, and more. This not only simplifies the setup process for the users but also ensures that they're starting with a setup that's tried-and-tested for compatibility and performance with Labelbox.\n",
    "Next, the script automatically installs essential Python libraries (\"labelbox\" and \"labelspark\") on the new cluster. These libraries are crucial for working with Labelbox services and getting the best out of the data labeling and management capabilities it offers.\n",
    "This script aims to streamline the initial setup process for Labelbox customers, making it easier for them to start using Labelbox with Databricks. By automating these setup tasks, users can start their data labeling and analysis tasks quickly, without worrying about the underlying setup and configurations.</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"left\">Add your Databricks instance URL and your access token</font></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "databricks_instance = \"<Your databricks instance URL>\" # Add your Databricks instance URL here. The URL can be found in the address bar of your Databricks workspace. It should be of the form <location>.gcp.databricks.com. \n",
    "personal_access_token = \"<Your personal access token>\" # Add your personal access token here. The token can be found in the User Settings page of your Databricks workspace."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"left\">Once you've added your instance URL and personal access token, run the bellow cell to create a cluster and attach the required libraries</font></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Remove 'https://' from the start of the URL\n",
    "if databricks_instance.startswith(\"https://\"):\n",
    "    databricks_instance = databricks_instance[8:]\n",
    "\n",
    "# Remove trailing slash from the end of the URL\n",
    "if databricks_instance.endswith(\"/\"):\n",
    "    databricks_instance = databricks_instance[:-1]\n",
    "\n",
    "# Function to create a Databricks cluster\n",
    "def create_cluster(personal_access_token, databricks_instance):\n",
    "    # JSON payload for the API request\n",
    "    json_payload = {\n",
    "        \"autoscale\": {\"min_workers\": 1, \"max_workers\": 10}, # Cluster autoscaling parameters\n",
    "        \"cluster_name\": \"Labelbox Worker\", # Name of the cluster\n",
    "        \"spark_version\": \"13.3.x-scala2.12\", # Spark version\n",
    "        \"gcp_attributes\": {\n",
    "            \"use_preemptible_executors\": False,\n",
    "            \"availability\": \"PREEMPTIBLE_WITH_FALLBACK_GCP\",\n",
    "            \"zone_id\": \"HA\"\n",
    "        }, # GCP-specific attributes\n",
    "        \"node_type_id\": \"n1-standard-4\", # Node type\n",
    "        \"driver_node_type_id\": \"n1-standard-4\", # Driver node type\n",
    "        \"ssh_public_keys\": [], # SSH public keys for secure connections\n",
    "        \"custom_tags\": {}, # Any custom tags to be associated with the cluster\n",
    "        \"cluster_log_conf\": {\"dbfs\": {\"destination\": \"dbfs:/cluster-logs\"}}, # Logging configuration\n",
    "        \"spark_env_vars\": {}, # Environment variables for Spark\n",
    "        \"autotermination_minutes\": 60, # Autotermination time in minutes\n",
    "        \"enable_elastic_disk\": False, # Whether to enable elastic disk\n",
    "        \"cluster_source\": \"UI\", # Source of the cluster creation\n",
    "        \"init_scripts\": [], # Initialization scripts\n",
    "        \"enable_local_disk_encryption\": False, # Whether to enable local disk encryption\n",
    "        \"runtime_engine\": \"STANDARD\", # Runtime engine\n",
    "    }\n",
    "\n",
    "    # Headers for the API request\n",
    "    headers = {\"Authorization\": f\"Bearer {personal_access_token}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    # Send the POST request to create a cluster\n",
    "    response = requests.post(\n",
    "        f\"https://{databricks_instance}/api/2.0/clusters/create\",\n",
    "        headers=headers,\n",
    "        data=json.dumps(json_payload)\n",
    "    )\n",
    "\n",
    "    # If the response is successful, print a message and return the cluster ID\n",
    "    if response.status_code == 200:\n",
    "        print(\"Cluster created successfully!\")\n",
    "        return json.loads(response.text)[\"cluster_id\"]\n",
    "    else:\n",
    "        # If the response is not successful, print an error message and return None\n",
    "        print(f\"Failed to create cluster. Status code: {response.status_code}\\nResponse: {response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function to install libraries in a Databricks cluster\n",
    "def install_libraries(cluster_id, personal_access_token, databricks_instance):\n",
    "    # Libraries to be installed\n",
    "    libraries = [\n",
    "        {\"pypi\": {\"package\": \"labelbox\"}},\n",
    "        {\"pypi\": {\"package\": \"labelspark\"}},\n",
    "    ]\n",
    "\n",
    "    # Payload for the API request\n",
    "    data = {\"cluster_id\": cluster_id, \"libraries\": libraries}\n",
    "\n",
    "    # Headers for the API request\n",
    "    headers = {\"Authorization\": \"Bearer \" + personal_access_token, \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    # Send the POST request to install the libraries\n",
    "    response = requests.post(f\"https://{databricks_instance}/api/2.0/libraries/install\", headers=headers, data=json.dumps(data))\n",
    "\n",
    "    # If the response is successful, print a message\n",
    "    if response.status_code == 200:\n",
    "        print(\"Libraries installed successfully!\")\n",
    "    else:\n",
    "        # If the response is not successful, print an error message\n",
    "        print(f\"Failed to install libraries. Status code: {response.status_code}\\nResponse: {response.text}\")\n",
    "\n",
    "# Create a cluster and get its ID\n",
    "cluster_id = create_cluster(personal_access_token, databricks_instance)\n",
    "\n",
    "# If the cluster was successfully created, install the libraries\n",
    "if cluster_id:\n",
    "    install_libraries(cluster_id, personal_access_token, databricks_instance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
