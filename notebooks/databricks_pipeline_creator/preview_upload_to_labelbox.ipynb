{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Labelspark (ls) for working with Labelbox and PySpark SQL for working with Spark\n",
    "import labelspark as ls\n",
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "\n",
    "# Retrieve the dataset ID from a widget input\n",
    "lb_dataset_id = dbutils.widgets.get(\"dataset_id\")\n",
    "\n",
    "# Retrieve the table path from a widget input\n",
    "table_name = dbutils.widgets.get(\"table_path\")\n",
    "\n",
    "# Retrieve the Labelbox API key from a widget input\n",
    "api_key = dbutils.widgets.get(\"labelbox_api_key\")\n",
    "\n",
    "# Retrieve the schema map from a widget input\n",
    "schema_map = json.loads(dbutils.widgets.get(\"schema_map\"))\n",
    "\n",
    "# Create a SparkSession to work with Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Run a SQL command to describe the extended properties of the table and store the result in table_info\n",
    "table_info = spark.sql(f\"DESCRIBE EXTENDED {table_name}\")\n",
    "\n",
    "# Extract the location from the table information and store it in table_path\n",
    "table_path = table_info.filter(\"col_name == 'Location'\").collect()[0]['data_type']\n",
    "\n",
    "# Fetch the first 50 rows from the table into a DataFrame\n",
    "temp_df = spark.sql(f\"SELECT * FROM {table_name} LIMIT 50\")\n",
    "\n",
    "# Define a path to save the temporary table. This assumes that `table_path` is a directory.\n",
    "temp_table_storage_path = f\"{table_path}_temp_50_rows\"\n",
    "\n",
    "# Write the DataFrame to the specified path with overwrite mode\n",
    "temp_df.write.format(\"delta\").mode(\"overwrite\").save(temp_table_storage_path)\n",
    "\n",
    "\n",
    "# Create a Labelspark client using the provided API key\n",
    "client = ls.Client(lb_api_key=api_key)\n",
    "\n",
    "# Use the saved location in the create_data_rows_from_delta_table function\n",
    "client.create_data_rows_from_delta_table(dataset_id=lb_dataset_id, table_path=temp_table_storage_path, column_mappings=schema_map, skip_duplicates=True, verbose=True, spark=spark)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
